{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:33:23.371510Z",
     "start_time": "2018-01-23T05:33:22.975014Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import json\n",
    "from functools import reduce\n",
    "path_prefix = 'hdfs://192.180.3.43:9000/phone_detail/'\n",
    "phone_detail = sc.textFile(path_prefix+'*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:33:33.658637Z",
     "start_time": "2018-01-23T05:33:33.653939Z"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T07:45:26.695169Z",
     "start_time": "2018-01-25T07:45:26.655192Z"
    }
   },
   "outputs": [],
   "source": [
    "pdetail_201705=sc.textFile(path_prefix+'merge201705.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:33:30.937169Z",
     "start_time": "2018-01-23T05:33:30.922988Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_schema(schemaString,typeString):\n",
    "    dict_getType = {'int':IntegerType(),'string':StringType(),'float':FloatType(),'bool':BooleanType()}\n",
    "    fields = [StructField(field_name, dict_getType.get(Type), True) \n",
    "              for field_name,Type in zip(schemaString.split(' '),typeString.split(' '))]\n",
    "    schema = StructType(fields)\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T07:45:36.870056Z",
     "start_time": "2018-01-25T07:45:36.863065Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_null(item):\n",
    "    return bool(item.strip())\n",
    "rdd1 = pdetail_201705.filter(remove_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T07:45:49.270039Z",
     "start_time": "2018-01-25T07:45:49.106855Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attrs = 'user_mobile real_name identity_code channel_src channel_attr created_time channel_type channel_code,file_people'\n",
    "attrs_type = 'string string string string string string string string bool'\n",
    "people_schema = get_schema(attrs,attrs_type)\n",
    "\n",
    "def get_people_basic_attr(item):\n",
    "    try:\n",
    "        itemj = json.loads(item)\n",
    "        items_list = [itemj.get(i) for i in attrs.split(' ')]\n",
    "        items_list[-1] = True\n",
    "        return itemj.get('user_mobile'),tuple(items_list)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        return None,None\n",
    "def reduce_repeat_item(x,y):\n",
    "    if x is None:\n",
    "        return y\n",
    "    if y is None:\n",
    "        return x\n",
    "    return x\n",
    "rdd40 = rdd1.map(get_people_basic_attr)\n",
    "rdd41 = rdd40.filter(lambda x:x[0] is not None)\n",
    "rdd42 = rdd41.reduceByKey(reduce_repeat_item).map(lambda x:x[1])\n",
    "people_raw_df = spark.createDataFrame(rdd42, people_schema)\n",
    "\n",
    "#people_raw_df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T03:34:57.833892Z",
     "start_time": "2018-01-25T03:34:57.828757Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T07:45:57.666978Z",
     "start_time": "2018-01-25T07:45:57.510874Z"
    }
   },
   "outputs": [],
   "source": [
    "def first_func(item):\n",
    "    user_mobile = None\n",
    "    try:\n",
    "        A_json = json.loads(item)\n",
    "        user_mobile = A_json.get('user_mobile')\n",
    "        call_list = [x['call_record'] for x in A_json['task_data']['call_info']]\n",
    "        all_call = reduce(lambda x,y:x+y,call_list)\n",
    "        all_call = [((item.get('call_other_number'),item.get('call_start_time')),\n",
    "                     (item.get('call_address'),int(item.get('call_time')),item.get('call_type_name'),user_mobile))\n",
    "                    for item in all_call]\n",
    "        return user_mobile,all_call\n",
    "    except Exception as e:\n",
    "        #raise e\n",
    "#         with open('/home/app/zx_error.log','a') as f:\n",
    "#             f.writelines(+str(e)+'\\n')\n",
    "        with open('/home/app/'+str(time.time())[:10],'w') as f2:\n",
    "            f2.write(item)\n",
    "        return user_mobile,[]\n",
    "\n",
    "#根据用户手机号合并统一用户不同日期文件\n",
    "rdd11 = rdd1.map(first_func).filter(lambda x:bool(x[1]))\n",
    "rdd2 = rdd11.reduceByKey(lambda x,y:list(dict(x+y).items()))\n",
    "# ## 去除无用通话记录\n",
    "# ### 去除通话列表无关属性\n",
    "rdd24 = rdd2.flatMap(lambda x:x[1])\n",
    "rdd25 = rdd24.map(lambda x:(x[0][0],int(x[1][1]),x[1][2],x[1][3]))\n",
    "#rdd25.persist()\n",
    "# ### 统计通话记录号码性质\n",
    "# # ### 自己给自己打电话记录数量占比\n",
    "# # ### 开头不为1的电话记录数量占比\n",
    "# # ### 长度不是11位的\n",
    "# # ### Type 不是主叫被叫的\n",
    "# rdd254 = rdd25.filter(lambda x:x[2] not in ('被叫','主叫'))\n",
    "# ### 去除非人类记录，保留合法号码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T07:46:50.325551Z",
     "start_time": "2018-01-25T07:46:50.299857Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[172] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd11.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T09:11:19.675681Z",
     "start_time": "2018-01-25T09:11:19.634768Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_nonhumanlist_func(item):\n",
    "     not(((item[0][0])=='1') or (len(item[0])==11) or (item[0]==item[3]))\n",
    "rdd26 = rdd25.filter(lambda item:(((item[0][0]=='1') and (len(item[0])==11)\n",
    "                                   and (item[0]!=item[3]) and (item[1]>0))))\n",
    "# ### 检查自己给自己打电话记录详情\n",
    "# # ### 检查  相互打电话重复记录\n",
    "#     if Type == '被叫':\n",
    "# ## 生成有向边属性\n",
    "# ### 调整RDD内容\n",
    "def edge_adjust_func(item):\n",
    "    phone1,phone2 = (item[3],item[0]) if item[2]=='主叫' else (item[0],item[3])\n",
    "    return (phone1,phone2,item[3]),(item[1],1)\n",
    "rdd3 = rdd26.map(edge_adjust_func)\n",
    "#### 边聚合去重统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T01:18:04.097120Z",
     "start_time": "2018-01-26T01:18:04.048239Z"
    }
   },
   "outputs": [],
   "source": [
    "# 分文件聚合两个人的通话记录\n",
    "rdd31 = rdd3.reduceByKey(lambda x,y:(x[0]+y[0],x[1]+y[1]))\n",
    "# 按通话记录(区分主被叫)聚合通话记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T01:18:25.238647Z",
     "start_time": "2018-01-26T01:18:25.232508Z"
    }
   },
   "outputs": [],
   "source": [
    "rdd32 = rdd31.map(lambda x:((x[0][0],x[0][1]),x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T09:11:28.424193Z",
     "start_time": "2018-01-25T09:11:28.384859Z"
    }
   },
   "outputs": [],
   "source": [
    "## 去除不同文件重复记录#去除主被叫重复记录的问题\n",
    "\n",
    "rdd33 = rdd32.reduceByKey(lambda x,y:x if x[1]>y[1] else y)\n",
    "rdd34 = rdd33.map(lambda x:(x[0][0],x[0][1],x[1][0],x[1][1]))\n",
    "rdd34.persist()\n",
    "\n",
    "# ### 找出有重复记录数据\n",
    "### 生成点边 DataFrame\n",
    "edgeString= \"src dst calltime_sum calltime_cnt\"\n",
    "edgeTString = \"string string int int\"\n",
    "edgeschema = get_schema(edgeString,edgeTString)\n",
    "edge_df = spark.createDataFrame(rdd34, edgeschema)\n",
    "#edge_df.persist()\n",
    "# # 整理个人属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:37:49.862963Z",
     "start_time": "2018-01-23T05:37:32.955754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5743013"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:33:55.018447Z",
     "start_time": "2018-01-23T05:33:54.923308Z"
    }
   },
   "outputs": [],
   "source": [
    "# 主叫时间统计\n",
    "rdd341 = rdd34.map(lambda x:(x[0],(x[2],x[3])))\n",
    "rdd342 = rdd341.reduceByKey(lambda x,y:(x[0]+y[0],x[1]+y[1]))\n",
    "rdd343 = rdd342.map(lambda x:(x[0],x[1][0],x[1][1]))\n",
    "callingschema= \"user_mobile callingtime_sum calling_cnt\"\n",
    "callingType = \"string int int\"\n",
    "schema = get_schema(callingschema,callingType)\n",
    "calling_df = spark.createDataFrame(rdd343, schema)\n",
    "\n",
    "# 被叫时间统计\n",
    "rdd344 = rdd34.map(lambda x:(x[1],(x[2],x[3])))\n",
    "rdd345 = rdd344.reduceByKey(lambda x,y:(x[0]+y[0],x[1]+y[1]))\n",
    "rdd346 = rdd345.map(lambda x:(x[0],x[1][0],x[1][1]))\n",
    "calledschema= \"user_mobile calledtime_sum called_cnt\"\n",
    "calledType = \"string int int\"\n",
    "schema = get_schema(calledschema,calledType)\n",
    "called_df = spark.createDataFrame(rdd346, schema)\n",
    "\n",
    "# 主叫被叫合并统计\n",
    "rdd346 = rdd342.union(rdd345)\n",
    "rdd347 = rdd346.reduceByKey(lambda x,y:(x[0]+y[0],x[1]+y[1]))\n",
    "rdd348 = rdd347.map(lambda x:(x[0],x[1][0],x[1][1]))\n",
    "callschema= \"user_mobile calltime_sum call_cnt\"\n",
    "callType = \"string int int\"\n",
    "schema = get_schema(callschema,callType)\n",
    "call_df = spark.createDataFrame(rdd348, schema)\n",
    "\n",
    "call_df1 = call_df.join(calling_df,on='user_mobile',how='left')\n",
    "call_df2 = call_df1.join(called_df,on='user_mobile',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:33:58.632801Z",
     "start_time": "2018-01-23T05:33:58.518553Z"
    }
   },
   "outputs": [],
   "source": [
    "# ### 统计个人通话次数，利用等个人属性\n",
    "def person_attr_func(item):\n",
    "    add_list = [address for k,(address,*other) in item[1]]\n",
    "    address_dict={k:add_list.count(k) for k in set(add_list)}\n",
    "    call_count = len(item[1]) if len(item[1])>0 else 0.00001\n",
    "    calltime_sum = sum([int(times) for k,(a,times,*b) in item[1]])\n",
    "    calltime_mean = calltime_sum/call_count    \n",
    "    return item[0],call_count,calltime_sum,calltime_mean,address_dict   \n",
    "rdd21 = rdd2.map(person_attr_func)\n",
    "rdd21.persist()\n",
    "schemaString= \"user_mobile call_count calltime_sum calltime_mean address_dict\"\n",
    "TypeString = \"string int int float string\"\n",
    "schema = get_schema(schemaString,TypeString)\n",
    "people_attr_df = spark.createDataFrame(rdd21, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:33:59.356452Z",
     "start_time": "2018-01-23T05:33:59.311592Z"
    }
   },
   "outputs": [],
   "source": [
    "people_df = call_df2.join(people_raw_df,on='user_mobile',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T08:35:14.769282Z",
     "start_time": "2018-01-19T08:35:14.378241Z"
    }
   },
   "outputs": [],
   "source": [
    "#peopledf.persist()\n",
    "people_df.repartition(1).write.save(path_prefix+'people_dfnew.csv',format='csv')\n",
    "edge_df.repartition(1).write.save(path_prefix+'edge_dfnew.csv',format='csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
